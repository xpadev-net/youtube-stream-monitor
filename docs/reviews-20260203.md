実装と要件の照合レポート
全体評価: 高い一致度（1件の齟齬を検出）
要件定義書 (docs/requirements.md)
と実装コードを網羅的に照合した結果、ほぼ全ての要件が正しく実装されています。
---
合致確認済み項目 (全て問題なし)
セクション: §3.1
項目: POST /api/v1/monitors（リクエスト/レスポンス、バリデーション、409重複チェック）
状態: OK
────────────────────────────────────────
セクション: §3.2
項目: DELETE /api/v1/monitors/{id}（レスポンス形式）
状態: OK
────────────────────────────────────────
セクション: §3.3
項目: GET /api/v1/monitors/{id}（health, statistics含む）
状態: OK
────────────────────────────────────────
セクション: §3.4
項目: GET /api/v1/monitors（status/limit/offsetフィルタ、pagination）
状態: OK
────────────────────────────────────────
セクション: §3.5
項目: エラーレスポンス形式（全8エラーコード）
状態: OK
────────────────────────────────────────
セクション: §4.1
項目: 全9種のWebhookイベント型
状態: OK
────────────────────────────────────────
セクション: §4.2
項目: コールバックペイロード構造
状態: OK
────────────────────────────────────────
セクション: §4.3
項目: イベント別dataフィールド（delayed, blackout, silence, recovered）
状態: OK
────────────────────────────────────────
セクション: §4.4
項目: リトライポリシー（3回、1s/2s/4s、10sタイムアウト）
状態: OK
────────────────────────────────────────
セクション: §4.4
項目: コールバック全失敗時にジョブ削除（monitor.error非発火）
状態: OK
────────────────────────────────────────
セクション: §6
項目: FFmpeg blackdetect/silencedetect
状態: OK
────────────────────────────────────────
セクション: §6.2
項目: 解析サイクル実行制御（バックプレッシャー）
状態: OK
────────────────────────────────────────
セクション: §6.6
項目: セグメントエラー60秒閾値
状態: OK
────────────────────────────────────────
セクション: §6.7
項目: 一時ファイル管理（/tmp/segments/{monitor_id}/）
状態: OK
────────────────────────────────────────
セクション: §7.1
項目: Worker動作モード（Waiting→Monitoring遷移）
状態: OK
────────────────────────────────────────
セクション: §7.3
項目: 配信開始遅延検出（stream.delayed）
状態: OK
────────────────────────────────────────
セクション: §7.5
項目: ポーリング間隔（30s→10s切替）
状態: OK
────────────────────────────────────────
セクション: §7.6
項目: 配信終了検出（EXT-X-ENDLIST, is_live, 判定優先順位）
状態: OK
────────────────────────────────────────
セクション: §7.6
項目: 定期is_liveチェック（5分間隔）
状態: OK
────────────────────────────────────────
セクション: §8.6
項目: 内部API（PUT /internal/v1/monitors/{id}/status）
状態: OK
────────────────────────────────────────
セクション: §9.1
項目: DBスキーマ（monitors, monitor_stats, monitor_events、全インデックス）
状態: OK
────────────────────────────────────────
セクション: §10.4
項目: 起動時Reconciliation（Missing/Zombie/Orphaned Pod）
状態: OK
────────────────────────────────────────
セクション: §12.1
項目: API Key認証（X-API-Key、constant-time比較）
状態: OK
────────────────────────────────────────
セクション: §12.2
項目: Webhook HMAC-SHA256署名（X-Signature-256, X-Timestamp）
状態: OK
────────────────────────────────────────
セクション: §12.3
項目: レート制限（作成10回/分、照会100回/分）
状態: OK
────────────────────────────────────────
セクション: §12
項目: TLS 1.2強制
状態: OK
────────────────────────────────────────
セクション: §8.7
項目: ヘルスチェック（/healthz, /readyz）
状態: OK
────────────────────────────────────────
セクション: §14.2
項目: 全環境変数
状態: OK
---
検出された齟齬（1件）
Waiting Mode での stream.ended Webhook 未送信
- 箇所: internal/worker/worker.go:195-202
- 要件: §4.1 — 配信が終了した場合、stream.ended イベントを発火する
- 実装: Waiting Mode で was_live / not_live を検出した場合、reportStatus
でDB状態を更新してPodを終了しているが、stream.ended Webhookが送信されていない
- 影響: 配信がWorkerの監視開始前に終了していた場合、コールバック先に stream.ended 通知が届かない
// worker.go:195-202 — sendWebhook呼び出しがない
case "was_live", "not_live":
    w.mu.Lock()
    w.streamStatus = db.StreamStatusEnded
    w.mu.Unlock()
    w.setState(StateCompleted)
    w.reportStatus(ctx, db.StatusCompleted, nil)
    return nil  // ← Webhook未送信でreturn
他の3箇所の stream.ended 発火（line 300: EXT-X-ENDLIST, line 498: segment error, line 582:
is_live定期チェック）では正しく sendWebhook が呼ばれています。
---
まとめ
実装は要件定義書に対して非常に高い忠実度で実装されています。唯一の齟齬は、Waiting
Modeにおける配信終了時の stream.ended Webhook未送信です。修正が必要な場合はお知らせください。
---
⏺ Security Review Report
Vuln 1: SSRF via DNS Rebinding in Webhook Sender: internal/webhook/webhook.go:56
- Severity: HIGH
- Confidence: 9/10
- Category: ssrf_dns_rebinding
- Description: The webhook Sender uses a plain http.Client (line 56-58) instead of the codebase's
SafeHTTPClient. While ValidateOutboundURL is called at line 76 before each send, the actual HTTP
request at line 102 goes through the unprotected client. This creates a TOCTOU
(time-of-check-time-of-use) window where DNS can rebind between validation and dial, allowing the
request to reach private IPs. The callback URL is fully user-controlled via POST /api/v1/monitors.
The retry logic (3 attempts with backoff) amplifies the attack window. Notably, the codebase
already has NewSafeHTTPClient which enforces IP checks at dial time — and recently applied it to
the manifest parser in commit 48cf8ba — but the webhook sender was missed.
- Exploit Scenario: Attacker creates a monitor with callback_url pointing to a DNS server they
control. During initial validation, DNS resolves to a public IP. When the worker sends a webhook
(on stream status change), the DNS rebinds to 169.254.169.254 (cloud metadata endpoint) or an
internal Kubernetes service IP like 10.96.0.1. The webhook HTTP request hits the internal service,
potentially exfiltrating cloud credentials or reaching internal APIs.
- Recommendation: Replace the plain http.Client in NewSender with validation.NewSafeHTTPClient(10 *
   time.Second) to enforce private IP checks at dial time, matching the pattern already used
elsewhere in the codebase.
---
コードベース全体レビュー: YouTube Stream Tracker
概要
YouTube配信の映像・音声品質をリアルタイムで監視するシステム。Gateway (API + K8s管理) と Worker
(配信セグメント分析) の2サービス構成で、Kubernetes上でワーカーPodを動的にスケジュールする設計。
全体評価
よく構造化されたGoプロジェクト。パッケージ分離、エラーハンドリング、セキュリティ対策が適切に実装さ
れている。以下、カテゴリ別に指摘事項を列挙する。
---
セキュリティ
良い点
- constant-time比較: API key認証で crypto/subtle.ConstantTimeCompare を使用 (middleware.go:40,60) —
   タイミング攻撃対策
- SSRF対策: validation.ValidateOutboundURL でプライベートIPへのアウトバウンド通信を拒否、DNS
rebinding対策のSafe HTTP Clientも実装済み
- Webhook署名: HMAC-SHA256によるWebhook署名とタイムスタンプ検証 (5分ウィンドウ)
- TLS 1.2最低バージョン強制: validation/url.go:87
- Kubernetes Secrets参照: Pod env varでSecretKeyRefを使用し、平文キーの露出を抑制
指摘事項
1. ffmpeg.go — コマンドインジェクションの潜在リスク (ffmpeg.go:109,140,201)
  - exec.CommandContext に渡される filePath はWorker内部で生成されるため直接的なリスクは低いが、入
力が外部起因（セグメントURL→ファイル名）であることを考慮すると、filepath.Clean
等でのサニタイズがあるとより堅固。
2. ytdlp.go — streamURLのコマンドライン引数注入 (ytdlp.go:77,118)
  -
streamURLをそのままコマンドライン引数に渡している。exec.CommandContextは引数をシェル経由せずに渡す
ので直接的なシェルインジェクションは起きないが、--を入れてオプションとして解釈されるのを防ぐべき。
3. Webhook HTTP Clientがリダイレクトを追跡する (webhook.go:56-58)
  - デフォルトのhttp.Clientを使用しているため、悪意あるcallback URLがリダイレクト経由で内部サービ
  にアクセスする可能性がある。validation.NewSafeHTTPClientを使うべき。
---
バグ・正確性
4. worker.go:98 — graceful shutdownでの引数不整合
  - w.gracefulShutdown(ctx) を呼ぶが、この時点で ctx
は既にキャンセル済み。内部でctxを使う操作があれば失敗する。現時点では問題ないが、将来的にgraceful
shutdown内で非同期処理を追加する場合に問題になる。
5. worker.go:247-263 — monitoringModeのselect文の問題
  - default: goto Analyze を含むselectが manifestRefreshTicker
のチャネルとctx.Doneをチェックしているが、default句があるためtickerのイベントを取りこぼす可能性が
  い。tickerイベントが来ていてもdefaultに落ちることがある。
6. reconcile.go:244-249 — 無意味なデシリアライズ
  - monitor.Config.CheckIntervalSec == 0 の場合に空JSON {} からデシリアライズして上書きしているが
  デフォルト値のゼロ値と意図的なゼロ値の区別がつかない。実質的に何もしないコード。
7. monitor_repository.go:458-474 — contains 関数の車輪の再発明
  - strings.Contains を使えば良いだけの場所で独自実装している。
---
設計・アーキテクチャ
8. マイグレーション管理の脆弱性 (db.go:64-81)
  - 単一のSQLファイルを毎回 Exec しており、マイグレーション履歴の管理がない。CREATE TABLE IF NOT
EXISTS で冪等性は確保されているが、今後スキーマ変更があるとカラム追加等を安全に実行できない。golang
  -migrate や goose 等の使用を検討すべき。
9. monitor_events テーブルが未活用
  - DBスキーマに monitor_events テーブルが定義され、リポジトリに CreateEvent, GetPendingEvents,
UpdateEventWebhookStatus があるが、Worker/Gatewayのどちらからも呼ばれていない。死コード。
10. DASH未実装 (manifest.go:204-208)
  - getLatestDASHSegment が常にエラーを返す。YouTube配信は主にHLSだが、明示的にDASH
URLも受け付けている。サポートしないなら早期にバリデーションで弾くべき。
11. Worker Podがbare Podとして作成されている (k8s.go:178-249)
  - DeploymentやJobではなくbare Podを直接作成している。RestartPolicy: OnFailure
が設定されているがPodが削除された場合は再作成されない。Reconcilerでカバーしているが、Kubernetes Job
   を使う方がより堅牢。
---
パフォーマンス
12. monitoringMode の30秒固定Manifest更新 (worker.go:233)
  - manifestの更新間隔がハードコードされている。configで制御可能にすべき。
13. セグメントの全データをメモリに読み込み (manifest.go:228)
  - io.ReadAll でセグメント全体をメモリに読む。10MBの上限があるが、同時に複数セグメント処理する場
  にメモリ圧迫の可能性。
---
テストカバレッジ
14. Workerパッケージにテストがない
  - worker.go, callback.go
にはテストファイルが存在しない。ビジネスロジックの中核であり、最もテストが必要な部分。
15. ffmpeg, manifest, ytdlp, validation パッケージにテストがない
  - 外部コマンド依存のためテストが書きにくいが、少なくともインターフェースを導入してモック可能にす
べき。
---
コード品質
16. handlers.go:40 — NewHandler引数が8個
  - 引数が多すぎる。構造体を受け取る形にリファクタすべき。
17. handlers.go:345-352, 435-443 — ステータスバリデーションの重複
  - validStatuses マップが ListMonitors と UpdateMonitorStatus
の両方で定義されている。共通関数に抽出すべき。
18. healthzHandler がDB引数を受け取るが使用していない (cmd/gateway/main.go:169-173)
  - database パラメータを受け取っているが、readyzHandler と違いDBチェックを行わない。引数が不要。
19. ログレベルの不統一
  - Gateway起動時のreconciliation失敗が log.Error
だが、処理は継続される。Workerのステータスレポート失敗が
log.Warn。重要度に基づいたログレベル方針を統一すべき。
---
優先度の高い修正推奨
┌────────┬───────────────────────────────────────────┬──────────────────────────┐
│ 優先度 │                   項目                    │           影響           │
├────────┼───────────────────────────────────────────┼──────────────────────────┤
│ 高     │ #3 Webhook SenderにSafe HTTP Clientを使用 │ SSRF脆弱性               │
├────────┼───────────────────────────────────────────┼──────────────────────────┤
│ 高     │ #5 monitoringModeのselectロジック修正     │ manifest更新の取りこぼし │
├────────┼───────────────────────────────────────────┼──────────────────────────┤
│ 高     │ #14 Workerのテスト追加                    │ コアロジックの信頼性     │
├────────┼───────────────────────────────────────────┼──────────────────────────┤
│ 中     │ #8 マイグレーション管理ツール導入         │ 運用上の安全性           │
├────────┼───────────────────────────────────────────┼──────────────────────────┤
│ 中     │ #9 死コードの整理                         │ 保守性                   │
├────────┼───────────────────────────────────────────┼──────────────────────────┤
│ 低     │ #16-18 コード整理                         │ 可読性                   │
└────────┴───────────────────────────────────────────┴──────────────────────────┘   